#!/usr/bin/env python

import sys
import json
import urlparse
import configparser

from wiki_graph import WikiGraph
from algorithm.bfs import BFS
from algorithm.iddfs import IDDFS
import api
from store.sqlitestore import SqliteStore
from store.neo4jstore import Neo4jStore

def find_path(start_page, end_page, algo, dbstore):
  graph = WikiGraph({'dbstore': dbstore})
  config = {
    "start_page": start_page,
    "end_page": end_page
  }
  path = graph.path(start_page['pageid'], end_page['pageid'])
  # got path no need to run algo
  if len(path) > 0:
    return map(lambda node: node['fullurl'], path)  
  algorithm = algo(config, graph)
  algorithm.run()
  return algorithm.path()

def find(pages, url):
  for page in pages:
    if(page["fullurl"] == url):
      return page
  return None

def title(url):
  path = urlparse.urlparse(url).path
  return path.split("/")[-1] 

def fetch_pages(start, end, dbstore):
  start_title = title(start)
  end_title = title(end)

  # read pages from db (might have been cached earlier)
  start_pages = dbstore.get_page_from_url_title(start_title)
  end_pages = dbstore.get_page_from_url_title(end_title) 

  # make single API call for missing pages
  missing_titles = []
  if(len(start_pages) == 0):
      missing_titles += [start_title]
  if(len(end_pages) == 0):
      missing_titles += [end_title]

  pages = []
  if(len(missing_titles) > 0):
    pages = api.info_for_titles(missing_titles)
    # save pages in db ( for caching )
    dbstore.save_pages(pages) 
  return start_pages + end_pages + pages

def get_store(config):
  defaults = config['defaults']
  which_store = defaults['dbstore']
  store_config = config[which_store]
  all_store = {
    'sqlitestore': SqliteStore,
    'neo4jstore': Neo4jStore
  }
  return all_store[which_store](store_config)
  

def main(start, end, algo, config):

  # initialize  database store object
  dbstore = get_store(config) 

  # fetch pages from db ( or network if not cached)
  pages = fetch_pages(start, end, dbstore) 
  start_page = find(pages, start)
  end_page = find(pages, end)

  # find path between the two pages 
  path = find_path(start_page, end_page, algo, dbstore)
  return { 
    "start": start,
    "end": end,
    "path": path
  }

def validate_input():
  # need one input
  if len(sys.argv) < 2:
    return (False, "", "")
  # input should be valid json with required keys
  try:
    jsn = json.loads(sys.argv[1])
    start = jsn["start"]
    end = jsn["end"]
  except Exception, e: 
    print "Invalid input JSON"
    return (False, "", "")
  return (True, start, end)

def usage():
  print("usage: " +  sys.argv[0] + ''' '{
    "start": "<starting article>",
    "end": "<ending article>"
  }' ''')

def read_config():
  cfg = configparser.ConfigParser()
  cfg.read('settings.cfg')
  return cfg

def get_algo(which_algo):
  all_algo = {
    'BFS': BFS,
    'IDDFS': IDDFS
  }
  return all_algo[which_algo]

if __name__ == "__main__":
  isvalid, start, end = validate_input()
  if(isvalid):
    cfg = read_config()
    algo = get_algo(cfg['defaults']['algo']) 
    output = main(start, end, algo, cfg)
    print json.dumps(output, indent=2, separators=(',', ': '))
  else:
    usage()
    exit(1)
